"""
PrintShop çŸ¥è¯†åº“å‘é‡æœç´¢æ¨¡å—
"""

import json
import numpy as np
from pathlib import Path
from typing import List, Dict, Optional
from dataclasses import dataclass


@dataclass
class SearchResult:
    """æœç´¢ç»“æœ"""
    id: str
    title: str
    content: str
    category: str
    path: str
    similarity: float


class KnowledgeSearch:
    """çŸ¥è¯†åº“å‘é‡æœç´¢å¼•æ“"""
    
    def __init__(self, embeddings_path: str):
        self.embeddings_path = Path(embeddings_path)
        self.documents: List[Dict] = []
        self.embeddings: np.ndarray = None
        self.model = None
        self.model_name: str = ""
        self._loaded = False
    
    def load(self) -> bool:
        """åŠ è½½å‘é‡æ–‡ä»¶åˆ°å†…å­˜"""
        if self._loaded:
            return True
            
        if not self.embeddings_path.exists():
            raise FileNotFoundError(f"å‘é‡æ–‡ä»¶ä¸å­˜åœ¨: {self.embeddings_path}")
        
        print(f"ğŸ“‚ åŠ è½½å‘é‡æ–‡ä»¶: {self.embeddings_path}")
        with open(self.embeddings_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        self.model_name = data["metadata"]["model"]
        self.documents = data["documents"]
        
        # æå–åµŒå…¥å‘é‡ä¸º numpy æ•°ç»„ï¼ˆåŠ é€Ÿè®¡ç®—ï¼‰
        self.embeddings = np.array([doc["embedding"] for doc in self.documents])
        
        print(f"âœ… åŠ è½½å®Œæˆ: {len(self.documents)} ä¸ªæ–‡æ¡£, ç»´åº¦ {self.embeddings.shape[1]}")
        self._loaded = True
        return True
    
    def load_model(self):
        """åŠ è½½ sentence-transformers æ¨¡å‹"""
        if self.model is not None:
            return
            
        try:
            from sentence_transformers import SentenceTransformer
            print(f"ğŸ¤– åŠ è½½æ¨¡å‹: {self.model_name}")
            self.model = SentenceTransformer(self.model_name)
            print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
        except ImportError:
            raise ImportError("éœ€è¦å®‰è£… sentence-transformers: pip install sentence-transformers")
    
    def encode_query(self, query: str) -> np.ndarray:
        """å°†æŸ¥è¯¢æ–‡æœ¬ç¼–ç ä¸ºå‘é‡"""
        self.load_model()
        return self.model.encode(query)
    
    def search(self, query: str, top_k: int = 5) -> List[SearchResult]:
        """
        æœç´¢æœ€ç›¸ä¼¼çš„æ–‡æ¡£
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        if not self._loaded:
            self.load()
        
        # ç¼–ç æŸ¥è¯¢
        query_embedding = self.encode_query(query)
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarities = self._cosine_similarity(query_embedding, self.embeddings)
        
        # è·å– top_k ç´¢å¼•
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        # æ„å»ºç»“æœ
        results = []
        for idx in top_indices:
            doc = self.documents[idx]
            results.append(SearchResult(
                id=doc["id"],
                title=doc["title"],
                content=doc["content"][:500],  # æˆªæ–­å†…å®¹
                category=doc["category"],
                path=doc["path"],
                similarity=float(similarities[idx])
            ))
        
        return results
    
    def search_with_embedding(self, query_embedding: np.ndarray, top_k: int = 5) -> List[SearchResult]:
        """
        ä½¿ç”¨é¢„è®¡ç®—çš„å‘é‡æœç´¢ï¼ˆç”¨äºå¤–éƒ¨ç¼–ç ï¼‰
        
        Args:
            query_embedding: æŸ¥è¯¢å‘é‡
            top_k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        if not self._loaded:
            self.load()
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarities = self._cosine_similarity(query_embedding, self.embeddings)
        
        # è·å– top_k ç´¢å¼•
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        # æ„å»ºç»“æœ
        results = []
        for idx in top_indices:
            doc = self.documents[idx]
            results.append(SearchResult(
                id=doc["id"],
                title=doc["title"],
                content=doc["content"][:500],
                category=doc["category"],
                path=doc["path"],
                similarity=float(similarities[idx])
            ))
        
        return results
    
    @staticmethod
    def _cosine_similarity(a: np.ndarray, b: np.ndarray) -> np.ndarray:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆå‘é‡ a ä¸çŸ©é˜µ b çš„æ¯ä¸€è¡Œï¼‰"""
        # å½’ä¸€åŒ–
        a_norm = a / np.linalg.norm(a)
        b_norm = b / np.linalg.norm(b, axis=1, keepdims=True)
        # ç‚¹ç§¯
        return np.dot(b_norm, a_norm)
    
    @property
    def stats(self) -> Dict:
        """è¿”å›ç»Ÿè®¡ä¿¡æ¯"""
        if not self._loaded:
            return {"loaded": False}
        
        categories = {}
        for doc in self.documents:
            cat = doc["category"]
            categories[cat] = categories.get(cat, 0) + 1
        
        return {
            "loaded": True,
            "model": self.model_name,
            "total_documents": len(self.documents),
            "embedding_dim": self.embeddings.shape[1] if self.embeddings is not None else 0,
            "categories": categories
        }
