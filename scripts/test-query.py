#!/usr/bin/env python3
"""
PrintShop çŸ¥è¯†åº“æŸ¥è¯¢æµ‹è¯•
ç”¨äºŽè”è°ƒæµ‹è¯•å‘é‡åµŒå…¥å’Œè¯­ä¹‰æœç´¢
"""

import json
import numpy as np
from pathlib import Path

EMBEDDINGS_FILE = Path(__file__).parent.parent / "embeddings" / "knowledge-vectors.json"


def cosine_similarity(a, b):
    """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))


def search(query_embedding, documents, top_k=5):
    """æœç´¢æœ€ç›¸ä¼¼çš„æ–‡æ¡£"""
    results = []
    for doc in documents:
        similarity = cosine_similarity(query_embedding, doc["embedding"])
        results.append({
            "title": doc["title"],
            "category": doc["category"],
            "path": doc["path"],
            "similarity": float(similarity)
        })
    
    results.sort(key=lambda x: x["similarity"], reverse=True)
    return results[:top_k]


def main():
    # æ£€æŸ¥å‘é‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not EMBEDDINGS_FILE.exists():
        print(f"âŒ å‘é‡æ–‡ä»¶ä¸å­˜åœ¨: {EMBEDDINGS_FILE}")
        print("è¯·å…ˆè¿è¡Œ generate-embeddings.py ç”Ÿæˆå‘é‡")
        return
    
    # åŠ è½½å‘é‡
    print(f"ðŸ“‚ åŠ è½½å‘é‡æ–‡ä»¶: {EMBEDDINGS_FILE}")
    with open(EMBEDDINGS_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    documents = data["documents"]
    print(f"âœ… åŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£å‘é‡")
    print(f"   æ¨¡åž‹: {data.get('model', 'unknown')}")
    print(f"   ç”Ÿæˆæ—¶é—´: {data.get('generated_at', 'unknown')}")
    
    # æµ‹è¯•æŸ¥è¯¢ï¼ˆéœ€è¦æ¨¡åž‹æ¥ç”ŸæˆæŸ¥è¯¢å‘é‡ï¼‰
    print("\n" + "=" * 50)
    print("æµ‹è¯•ç”¨ä¾‹ï¼ˆéœ€è¦ sentence-transformers ç”ŸæˆæŸ¥è¯¢å‘é‡ï¼‰")
    print("=" * 50)
    
    test_queries = [
        "åç‰‡æŠ¥ä»·å¤šå°‘é’±",
        "å–·ç»˜ç”¨ä»€ä¹ˆææ–™",
        "ç”»å†Œè£…è®¢å·¥è‰º",
        "ä¼ä¸šæ´»åŠ¨ç‰©æ–™",
        "VIè®¾è®¡æœåŠ¡"
    ]
    
    try:
        from sentence_transformers import SentenceTransformer
        model = SentenceTransformer(data.get("model", "paraphrase-multilingual-MiniLM-L12-v2"))
        
        for query in test_queries:
            print(f"\nðŸ” æŸ¥è¯¢: {query}")
            query_embedding = model.encode(query)
            results = search(query_embedding, documents, top_k=3)
            
            for i, r in enumerate(results, 1):
                print(f"   {i}. [{r['category']}] {r['title']} (ç›¸ä¼¼åº¦: {r['similarity']:.3f})")
    
    except ImportError:
        print("\nâš ï¸ æœªå®‰è£… sentence-transformersï¼Œæ— æ³•ç”ŸæˆæŸ¥è¯¢å‘é‡")
        print("ä»…æ˜¾ç¤ºå·²åŠ è½½çš„æ–‡æ¡£åˆ—è¡¨ï¼š")
        for doc in documents[:10]:
            print(f"   - [{doc['category']}] {doc['title']}")
        if len(documents) > 10:
            print(f"   ... è¿˜æœ‰ {len(documents) - 10} ä¸ªæ–‡æ¡£")


if __name__ == "__main__":
    main()
